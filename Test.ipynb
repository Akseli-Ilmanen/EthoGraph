{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1eebe90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import vocalpy as voc\n",
    "from ethograph.features.energy import bandpass_envelope\n",
    "\n",
    "sound = voc.Sound.read(\"path/to/audio.wav\")\n",
    "data = sound.data[0]  # first channel, 1-D\n",
    "rate = sound.samplerate\n",
    "\n",
    "env_time, envelope = bandpass_envelope(data, rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246051e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import vocalpy as voc\n",
    "from ethograph.features.energy import env_ava\n",
    "\n",
    "sound = voc.Sound.read(\"path/to/audio.wav\")\n",
    "data = sound.data[0]  # first channel, 1-D\n",
    "sample_rate = sound.samplerate\n",
    "\n",
    "env_time, envelope = env_ava(\n",
    "    audio_data_1d, sample_rate,\n",
    "    nperseg=102,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f0cf8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import vocalpy as voc\n",
    "from vocalseg.dynamic_thresholding import dynamic_threshold_segmentation\n",
    "\n",
    "sound = voc.Sound.read(\"path/to/audio.wav\")\n",
    "data = sound.data[0]  # first channel, 1-D\n",
    "rate = sound.samplerate\n",
    "\n",
    "results = dynamic_threshold_segmentation(\n",
    "    data, rate,\n",
    "    min_level_db=-70.0,\n",
    "    hop_length_ms=5.0,\n",
    "    silence_threshold=0.1,\n",
    "    min_syllable_length_s=0.02,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eae44b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function dynamic_threshold_segmentation in module vocalseg.dynamic_thresholding:\n",
      "\n",
      "dynamic_threshold_segmentation(vocalization, rate, min_level_db=-80, min_level_db_floor=-40, db_delta=5, n_fft=1024, hop_length_ms=1, win_length_ms=5, ref_level_db=20, pre=0.97, silence_threshold=0.05, min_silence_for_spec=0.1, max_vocal_for_spec=1.0, min_syllable_length_s=0.1, spectral_range=None, verbose=False)\n",
      "    computes a spectrogram from a waveform by iterating through thresholds\n",
      "         to ensure a consistent noise level\n",
      "\n",
      "    Arguments:\n",
      "        vocalization {[type]} -- waveform of song\n",
      "        rate {[type]} -- samplerate of datas\n",
      "\n",
      "    Keyword Arguments:\n",
      "        min_level_db {int} -- default dB minimum of spectrogram (threshold anything below) (default: {-80})\n",
      "        min_level_db_floor {int} -- highest number min_level_db is allowed to reach dynamically (default: {-40})\n",
      "        db_delta {int} -- delta in setting min_level_db (default: {5})\n",
      "        n_fft {int} -- FFT window size (default: {1024})\n",
      "        hop_length_ms {int} -- number audio of frames in ms between STFT columns (default: {1})\n",
      "        win_length_ms {int} -- size of fft window (ms) (default: {5})\n",
      "        ref_level_db {int} -- reference level dB of audio (default: {20})\n",
      "        pre {float} -- coefficient for preemphasis filter (default: {0.97})\n",
      "        min_syllable_length_s {float} -- shortest expected length of syllable (default: {0.1})\n",
      "        min_silence_for_spec {float} -- shortest expected length of silence in a song (used to set dynamic threshold) (default: {0.1})\n",
      "        silence_threshold {float} -- threshold for spectrogram to consider noise as silence (default: {0.05})\n",
      "        max_vocal_for_spec {float} -- longest expected vocalization in seconds  (default: {1.0})\n",
      "        spectral_range {[type]} -- spectral range to care about for spectrogram (default: {None})\n",
      "        verbose {bool} -- display output (default: {False})\n",
      "\n",
      "\n",
      "    Returns:\n",
      "        [results] -- [dictionary of results]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import audioio as aio\n",
    "from vocalseg.dynamic_thresholding import dynamic_threshold_segmentation\n",
    "\n",
    "audio_path = \"path/to/audio.wav\"\n",
    "data, sample_rate = aio.load_audio(audio_path)\n",
    "if data.ndim > 1:\n",
    "    data = data[:, 0]  # select first channel\n",
    "rate = float(sample_rate)\n",
    "\n",
    "results = dynamic_threshold_segmentation(data, rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cb3aaeb",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'vocalseg' has no attribute 'dynamic_threshold_segmentation'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvocalseg\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mvocalseg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdynamic_threshold_segmentation\u001b[49m\n",
      "\u001b[31mAttributeError\u001b[39m: module 'vocalseg' has no attribute 'dynamic_threshold_segmentation'"
     ]
    }
   ],
   "source": [
    "import vocalseg\n",
    "vocalseg.dynamic_threshold_segmentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348eaf7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import audioio as aio\n",
    "\n",
    "audio_path = \"path/to/audio.wav\"\n",
    "data, sample_rate = aio.load_audio(audio_path)\n",
    "if data.ndim > 1:\n",
    "    data = data[:, 0]  # select first channel\n",
    "rate = float(sample_rate)\n",
    "\n",
    "results = (data, rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b83d385b",
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'C:\\\\Users\\\\aksel\\\\Documents\\\\Code\\\\EthoGraph\\\\data2'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mPermissionError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     12\u001b[39m dest = Path(\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mC:\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mUsers\u001b[39m\u001b[33m\\\u001b[39m\u001b[33maksel\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mDocuments\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mCode\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mEthoGraph\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mdata2\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     13\u001b[39m dest.mkdir(parents=\u001b[38;5;28;01mTrue\u001b[39;00m, exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m \u001b[43masset\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdownload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\aksel\\anaconda3\\envs\\ethograph\\Lib\\site-packages\\dandi\\dandiapi.py:1690\u001b[39m, in \u001b[36mBaseRemoteAsset.download\u001b[39m\u001b[34m(self, filepath, chunk_size)\u001b[39m\n\u001b[32m   1683\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1684\u001b[39m \u001b[33;03mDownload the asset to ``filepath``.  Blocks until the download is\u001b[39;00m\n\u001b[32m   1685\u001b[39m \u001b[33;03mcomplete.\u001b[39;00m\n\u001b[32m   1686\u001b[39m \n\u001b[32m   1687\u001b[39m \u001b[33;03m:raises ValueError: if the asset is not backed by a blob\u001b[39;00m\n\u001b[32m   1688\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1689\u001b[39m downloader = \u001b[38;5;28mself\u001b[39m.get_download_file_iter(chunk_size=chunk_size)\n\u001b[32m-> \u001b[39m\u001b[32m1690\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mwb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m fp:\n\u001b[32m   1691\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m downloader(\u001b[32m0\u001b[39m):\n\u001b[32m   1692\u001b[39m         fp.write(chunk)\n",
      "\u001b[31mPermissionError\u001b[39m: [Errno 13] Permission denied: 'C:\\\\Users\\\\aksel\\\\Documents\\\\Code\\\\EthoGraph\\\\data2'"
     ]
    }
   ],
   "source": [
    "from dandi.dandiapi import DandiAPIClient\n",
    "\n",
    "client = DandiAPIClient()\n",
    "dandiset = client.get_dandiset(\"000231\", \"0.220904.1554\")\n",
    "\n",
    "asset = dandiset.get_asset_by_path(\n",
    "    \"sub-KM131/sub-KM131_ses-20180116T184757_behavior+ecephys+image.nwb\"\n",
    ")\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "dest = Path(r\"C:\\Users\\aksel\\Documents\\Code\\EthoGraph\\data2\")\n",
    "dest.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "asset.download(str(dest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fadc575",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ethograph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
