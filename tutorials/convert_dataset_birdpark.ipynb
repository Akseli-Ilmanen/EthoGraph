{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88a6b5e9",
   "metadata": {},
   "source": [
    "# Birdpark Dataset Conversion\n",
    "\n",
    "Data from Rüttimann et al. (2024)¹ ([paper](https://peerj.com/articles/20203), [zenodo](https://zenodo.org/records/13144875)), a multimodal dataset of zebra finch groups with synchronized video, microphone arrays, and backpack-mounted vibration transducer (accelerometers). \n",
    "\n",
    "The code belows how one can convert that existing dataset into the `Trials.nc` format. The sampling rate of the vibration transducer is very high (24kHz), therefore if the bottom plot loads very slowly, you may consider using the `Downsample` button in `I/0`.\n",
    "\n",
    "---\n",
    "\n",
    "¹ Rüttimann, L., Wang, Y., Rychen, J., Tomka, T., Hörster, H., & Hahnloser, R. H. R. (2025). Multimodal system for recording individual-level behaviors in songbird groups. PeerJ, 13, e20203. https://doi.org/10.7717/peerj.20203\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ab3973",
   "metadata": {},
   "source": [
    "<img src=\"assets/birdpark1.png\" width=\"900\">\n",
    "\n",
    "Adapated from Rüttimann et al. (2024)¹ - Fig. 1A-B, Fig. 2C\n",
    "\n",
    "<img src=\"assets/birdpark2.png\" width=\"1200\">\n",
    "\n",
    "GUI screenshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78539d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import h5py\n",
    "import requests\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "from audioio import write_audio\n",
    "from ethograph import set_media_attrs, minimal_basics, get_project_root\n",
    "\n",
    "project_root = Path.cwd().parent\n",
    "os.chdir(project_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84866546",
   "metadata": {},
   "source": [
    "### Explore snippet\n",
    "\n",
    "Example data from the birdpark dataset (a 7-second snippet from the `copExpBP08` recording) is available in:\n",
    "\n",
    "- `data/examples/copExpBP08_trim.mp4` - Video file\n",
    "- `data/examples/copExpBP08_trim.wav` - Audio file\n",
    "- `data/examples/copExpBP08_trim.nc` - Accelerometer data and metadata\n",
    "\n",
    "You can open these files directly from the GUI to explore the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b4bc2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f7e415be",
   "metadata": {},
   "source": [
    "### Download dataset\n",
    "\n",
    "You can download the entire dataset from [here](https://zenodo.org/records/13144875) or use the code below. I only tested the `copExpBP08` recording. If problems arise, the ReadMe [here](https://zenodo.org/records/13144875) is very helpful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63cae97c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checksum matches: Data.zip\n",
      "Downloaded: C:\\Users\\aksel\\Documents\\Code\\EthoGraph\\data\\Data.zip\n",
      "Extracting Data.zip...\n",
      "Extracted to: C:\\Users\\aksel\\Documents\\Code\\EthoGraph\\data\n"
     ]
    }
   ],
   "source": [
    "data_folder = get_project_root() / \"data\" / \"birdpark\"\n",
    "\n",
    "\n",
    "\n",
    "response = requests.get(\"https://zenodo.org/api/records/13144875\")\n",
    "data = response.json()\n",
    "\n",
    "for file in data['files']:\n",
    "    if file['checksum'] == \"md5:32d1ae6049556c803f68b6d354c952ca\":\n",
    "        print(f\"Checksum matches: {file['key']}\")\n",
    "        download_url = file['links']['self']\n",
    "        \n",
    "        output_path = data_folder / file['key']\n",
    "        response = requests.get(download_url, stream=True)\n",
    "        with open(output_path, 'wb') as f:\n",
    "            for chunk in response.iter_content(chunk_size=8192):\n",
    "                f.write(chunk)\n",
    "        \n",
    "        print(f\"Downloaded: {output_path}\")\n",
    "        \n",
    "        # Unzip if it's a zip file\n",
    "        if output_path.suffix == '.zip':\n",
    "            print(f\"Extracting {output_path.name}...\")\n",
    "            with zipfile.ZipFile(output_path, 'r') as zip_ref:\n",
    "                zip_ref.extractall(data_folder)\n",
    "            print(f\"Extracted to: {data_folder}\")\n",
    "        \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8ac4a5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fps = 47.6837158203125\n",
    "audio_sr = 24414.0625 # audio and accelerometer sampling rate\n",
    "\n",
    "h5_path = data_folder / \"copExpBP08\" / \"BP_2021-05-25_08-12-51_655154_0380000.h5\"\n",
    "video_path = data_folder / \"copExpBP08\" / \"BP_2021-05-25_08-12-51_655154_0380000.mp4\"\n",
    "audio_path = video_path.with_suffix('.wav')\n",
    "nc_path = video_path.with_suffix('.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3716b63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get file object\n",
    "f1 = h5py.File(h5_path, 'r')\n",
    "\n",
    "# read main data\n",
    "radioSignals = f1['/radioSignals'][()] # accelerometer transmitter device signals (one row per channel)\n",
    "daqSignals = f1['/daqSignals'][()] # microphone signals (one row per channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689c3005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create .wav file with microphone channels\n",
    "write_audio(audio_path, daqSignals.T, audio_sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "14e9f516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted type_vars_dict: {'individuals': array(['male (red radio)', 'female (yellow radio)'], dtype='<U21'), 'cameras': array(['cam1'], dtype='<U4'), 'mics': array(['mic1'], dtype='<U4'), 'features': ['vibration'], 'trial_conditions': []}\n"
     ]
    }
   ],
   "source": [
    "# Setup Trials.nc\n",
    "time_coords = np.arange(radioSignals.shape[1]) / audio_sr\n",
    "\n",
    "ds = xr.Dataset(\n",
    "        data_vars={\n",
    "            \"vibration\": xr.DataArray(\n",
    "                radioSignals.T,\n",
    "                dims=[\"time\", \"individuals\"],\n",
    "            ),\n",
    "        },\n",
    "        coords={\n",
    "            \"time\": time_coords,\n",
    "            \"individuals\": [\"male (red radio)\", \"female (yellow radio)\"], # Specific to copExpBP08\n",
    "        },\n",
    "        attrs={\n",
    "            \"fps\": fps,\n",
    "            \"audio_sr\": audio_sr\n",
    "            \n",
    "        }\n",
    "    )\n",
    "\n",
    "ds = set_media_attrs(\n",
    "        ds,\n",
    "        cameras=[video_path.name],\n",
    "        mics=[audio_path.name])\n",
    "\n",
    "dt = minimal_basics(ds)\n",
    "dt.to_netcdf(nc_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ethograph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
