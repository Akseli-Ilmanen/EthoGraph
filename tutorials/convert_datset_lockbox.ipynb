{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d507f91",
   "metadata": {},
   "source": [
    "# Lockbox Dataset Conversion\n",
    "\n",
    "Dataset from Reiske et al., 2025¹, containing video and pose files of individual mice solving mechanical puzzle \"lockboxes\" recorded from three camera perspectives (top, front, side).\n",
    "\n",
    "- Full dataset: https://doi.org/10.14279/depositonce-23850\n",
    "- Subset of dataset (used here): https://www.dropbox.com/scl/fo/h7nkai8574h23qfq9m1b2/AP4gNZOpDJJ7z0yGtbWQiOc?rlkey=w36jzxqjkghg0j0xva5zsxy2v&st=5r9msqjw&dl=0\n",
    "\n",
    "---\n",
    "\n",
    "¹ Reiske, P., Boon, M. N., Andresen, N., Traverso, S., Hohlbaum, K., Lewejohann, L., Thöne-Reineke, C., Hellwich, O., & Sprekeler, H. (2025). Mouse Lockbox Dataset: Behavior Recognition for Mice Solving Lockboxes (arXiv:2505.15408). arXiv. https://doi.org/10.48550/arXiv.2505.15408\n",
    "\n",
    "\n",
    "<img src=\"assets/lockbox1.png\" width=\"700\">\n",
    "\n",
    "From Fig. 1 in Reiske et al., 2025¹\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffbf1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import xarray as xr\n",
    "import requests\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from movement.kinematics import compute_velocity, compute_speed\n",
    "from movement.utils.vector import compute_norm\n",
    "from movement.filtering import filter_by_confidence\n",
    "from movement.io import load_poses, save_poses\n",
    "\n",
    "from ethograph import TrialTree, set_media_attrs, minimal_basics, get_project_root\n",
    "\n",
    "\n",
    "\n",
    "def download_and_extract(url: str, data_folder: Path) -> None:\n",
    "    zip_path = data_folder / \"dataset.zip\"\n",
    "    data_folder.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    response = requests.get(url, stream=True)\n",
    "    response.raise_for_status()\n",
    "    \n",
    "    with open(zip_path, 'wb') as f:\n",
    "        for chunk in response.iter_content(chunk_size=8192):\n",
    "            f.write(chunk)\n",
    "    \n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(data_folder)\n",
    "    \n",
    "    zip_path.unlink()\n",
    "\n",
    "\n",
    "data_folder = get_project_root() / \"data\" / \"lockbox\"\n",
    "os.makedirs(data_folder, exist_ok=True)\n",
    "url = \"https://www.dropbox.com/scl/fo/h7nkai8574h23qfq9m1b2/AP4gNZOpDJJ7z0yGtbWQiOc?rlkey=w36jzxqjkghg0j0xva5zsxy2v&e=1&st=5r9msqjw&dl=1\"\n",
    "\n",
    "download_and_extract(url, data_folder)\n",
    "\n",
    "data_folder = data_folder / \"labeled\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccadd32f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted type_vars_dict: {'individuals': array(['individual_0'], dtype='<U12'), 'cameras': array(['2021-02-15_07-32-44_segment1_mouse324_ball_front-view.avi',\n",
      "       '2021-02-15_07-32-44_segment1_mouse324_ball_side-view.avi',\n",
      "       '2021-02-15_07-32-44_segment1_mouse324_ball_top-down-view.avi'],\n",
      "      dtype='<U60'), 'pose': array(['2021-02-15_07-32-44_segment1_mouse324_ball_front-view-tracks_individual_0.csv',\n",
      "       '2021-02-15_07-32-44_segment1_mouse324_ball_side-view-tracks_individual_0.csv',\n",
      "       '2021-02-15_07-32-44_segment1_mouse324_ball_top-down-view-tracks_individual_0.csv'],\n",
      "      dtype='<U80'), 'features': ['position', 'confidence', 'front_velocity', 'front_speed', 'topview_distance_head_lever_tip', 'topview_distance_head_stick_head', 'topview_distance_head_ball'], 'space': array(['x', 'y'], dtype='<U1'), 'keypoints': array(['nose', 'ear_left', 'ear_right', 'front_paw_left',\n",
      "       'front_paw_right', 'back_paw_left', 'back_paw_right', 'tail_base',\n",
      "       'lever_tip', 'other_lever_tip', 'stick_head', 'ball',\n",
      "       'sliding_door'], dtype='<U15'), 'trial_conditions': []}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "fps = 30\n",
    "\n",
    "trials = [\n",
    "    \"2021-02-15_07-32-44_segment1\",\n",
    "    \"2021-03-05_08-36-42_segment1\",\n",
    "    \"2021-05-24_07-36-05_segment1\",\n",
    "    \"2021-05-25_08-19-50_segment2\",\n",
    "    \"2021-05-31_07-34-21_segment2\", \n",
    "    \"2021-05-31_07-34-21_segment3\",\n",
    "    \n",
    "]\n",
    "\n",
    "ds_list = []\n",
    "for trial in trials:\n",
    "    files = list(data_folder.glob(f\"{trial}*\"))\n",
    "    dlc_files = [f for f in files if f.suffix == '.h5']\n",
    "    # https://ethograph.readthedocs.io/en/latest/troubleshooting/ -> ideally replace .avi with .mp4\n",
    "    cam_names = [f.name for f in files if f.suffix == '.mp4'] # .avi\n",
    "    dlc_names = []\n",
    "    \n",
    "    trial_datasets = {}\n",
    "    \n",
    "    for file in dlc_files:\n",
    "        df = pd.read_hdf(file)\n",
    "        ds = load_poses.from_dlc_style_df(df, fps=fps)\n",
    "        \n",
    "        csv_path = str(file).replace('.h5', '.csv')\n",
    "        save_poses.to_dlc_file(ds, csv_path)\n",
    "        dlc_names.append(Path(csv_path).name.replace('.csv', '_individual_0.csv'))\n",
    "        \n",
    "        # A bit confusing to work with features that differ depending on the camera \n",
    "        # position. Ideally replace with 3D triangulated data, \n",
    "        # see Methods in https://doi.org/10.1101/2024.07.29.605658 \n",
    "        if \"front-view\" in str(file):    \n",
    "            \n",
    "            ds[\"front_velocity\"] = compute_velocity(ds.position)\n",
    "            ds[\"front_speed\"] = compute_speed(ds.position)\n",
    "            trial_datasets[\"front\"] = ds\n",
    "            \n",
    "        elif \"top-down-view\" in str(file):\n",
    "            head_centre_pos = ds.position.sel(\n",
    "                keypoints=[\"ear_left\", \"ear_right\"]\n",
    "            ).mean(\"keypoints\")\n",
    "\n",
    "            topview_pos = ds[\"position\"]\n",
    "            \n",
    "            ds[\"topview_distance_head_lever_tip\"] = compute_norm(\n",
    "                ds.position.sel(keypoints='lever_tip') - head_centre_pos\n",
    "            )\n",
    "            ds[\"topview_distance_head_stick_head\"] = compute_norm(\n",
    "                ds.position.sel(keypoints='stick_head') - head_centre_pos\n",
    "            )\n",
    "            ds[\"topview_distance_head_ball\"] = compute_norm(\n",
    "                ds.position.sel(keypoints='ball') - head_centre_pos\n",
    "            )\n",
    "            trial_datasets[\"top\"] = ds\n",
    "    \n",
    "    ds_merged = xr.merge(trial_datasets.values(), compat='override')\n",
    "    \n",
    "    \n",
    "    ds_merged[\"position\"] = topview_pos \n",
    "    \n",
    "    for var in ds_merged.data_vars:\n",
    "        ds_merged[var].attrs[\"type\"] = \"features\"\n",
    "    \n",
    "    ds_merged.attrs[\"trial\"] = trial\n",
    "    ds_merged = set_media_attrs(ds_merged, cameras=cam_names, pose=dlc_names)\n",
    "    ds_list.append(ds_merged)\n",
    "\n",
    "dt = TrialTree.from_datasets(ds_list)\n",
    "dt.save(data_folder / \"lockbox.nc\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
