{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4894b3c5",
   "metadata": {},
   "source": [
    "## two cells below i used for for whisker, i think"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba6f7fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (65033216, 56)\n",
      "Rate: 29999.989041455377\n",
      "Starting time: 399.0283126054678\n",
      "\n",
      "Units: 14\n",
      "('inhibitory', 'depth', 'layer', 'neuron_channel', 'spike_times', 'obs_intervals')\n"
     ]
    }
   ],
   "source": [
    "import pynwb\n",
    "import numpy as np\n",
    "\n",
    "nwb_path = r\"C:\\Users\\aksel\\Documents\\Code\\EthoGraph\\data\\sub-KF134_ses-20180211T154918_behavior+ecephys+image.nwb\"\n",
    "\n",
    "with pynwb.NWBHDF5IO(nwb_path, \"r\") as io:\n",
    "    nwb = io.read()\n",
    "    \n",
    "    # Raw ephys - this is the broadband data you can feed to KS4\n",
    "    ephys = nwb.acquisition[\"extracellular array recording\"]\n",
    "    print(f\"Shape: {ephys.data.shape}\")       # (65033216, 56) = samples x channels\n",
    "    print(f\"Rate: {ephys.rate}\")               # ~30kHz\n",
    "    print(f\"Starting time: {ephys.starting_time}\")  # offset into video timebase\n",
    "    \n",
    "    # Already spike-sorted units\n",
    "    print(f\"\\nUnits: {len(nwb.units)}\")\n",
    "    print(nwb.units.colnames)\n",
    "    \n",
    "    # To extract raw data for KS4 (careful - large!):\n",
    "    raw = ephys.data[:]  # loads full array into RAM\n",
    "    np.save(\"raw_ephys.npy\", raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fed6bb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.60 GB  sub-KF134/sub-KF134_ses-20180211T154918_behavior+ecephys+image/26871407-4821-4cd0-bde7-38e14b3c13ba_external_file_0.mkv\n"
     ]
    }
   ],
   "source": [
    "from dandi.dandiapi import DandiAPIClient\n",
    "from pathlib import Path\n",
    "\n",
    "client = DandiAPIClient()\n",
    "dandiset = client.get_dandiset(\"000231\", \"0.220904.1554\")\n",
    "\n",
    "for asset in dandiset.get_assets():\n",
    "    if \"KF134\" in asset.path and \"20180211T154918\" in asset.path and \"mkv\" in asset.path:\n",
    "        print(f\"{asset.size/1e9:.2f} GB  {asset.path}\")\n",
    "        asset.download(Path(r\"data\\whisker_video_ephys.mkv\"))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c549727f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544fcf81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fb846c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc09a01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "418c010c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acquisition: ['behavioral video', 'extracellular array recording']\n",
      "Processing: ['behavior']\n",
      "Units: units pynwb.misc.Units at 0x2514637048192\n",
      "Fields:\n",
      "  colnames: ['inhibitory' 'depth' 'layer' 'neuron_channel' 'spike_times'\n",
      " 'obs_intervals']\n",
      "  columns: (\n",
      "    inhibitory <class 'hdmf.common.table.VectorData'>,\n",
      "    depth <class 'hdmf.common.table.VectorData'>,\n",
      "    layer <class 'hdmf.common.table.VectorData'>,\n",
      "    neuron_channel <class 'hdmf.common.table.VectorData'>,\n",
      "    spike_times_index <class 'hdmf.common.table.VectorIndex'>,\n",
      "    spike_times <class 'hdmf.common.table.VectorData'>,\n",
      "    obs_intervals_index <class 'hdmf.common.table.VectorIndex'>,\n",
      "    obs_intervals <class 'hdmf.common.table.VectorData'>\n",
      "  )\n",
      "  description: Autogenerated by NWBFile\n",
      "  id: id <class 'hdmf.common.table.ElementIdentifiers'>\n",
      "  waveform_unit: volts\n",
      "\n",
      "Trials:     start_time  stop_time  direct_delivery  stim_is_random  optogenetic  \\\n",
      "id                                                                        \n",
      "88     399.820    407.425            False            True        False   \n",
      "89     407.425    414.990            False            True        False   \n",
      "90     414.990    421.840            False            True        False   \n",
      "91     421.840    428.650            False            True        False   \n",
      "92     428.650    435.385            False            True        False   \n",
      "\n",
      "    outcome choice rewarded_side servo_position stimulus  ignore_trial  \\\n",
      "id                                                                       \n",
      "88  correct   left          left          close  concave         False   \n",
      "89  correct  right         right         medium   convex         False   \n",
      "90  correct   left          left          close  concave         False   \n",
      "91  correct  right         right         medium   convex         False   \n",
      "92  correct  right         right          close   convex         False   \n",
      "\n",
      "    choice_time  response_window_open_time  trial  \n",
      "id                                                 \n",
      "88      403.447                    402.841     88  \n",
      "89      411.445                    410.446     89  \n",
      "90      418.100                    418.012     90  \n",
      "91      425.201                    424.861     91  \n",
      "92      431.819                    431.672     92  \n",
      "Electrodes:      x      y   z  imp                                           location  \\\n",
      "id                                                                          \n",
      "0  NaN   33.5 NaN  NaN  barrel cortex, (approx) layer L1, Intan channe...   \n",
      "1  NaN   53.5 NaN  NaN  barrel cortex, (approx) layer L1, Intan channe...   \n",
      "2  NaN   73.5 NaN  NaN  barrel cortex, (approx) layer L1, Intan channe...   \n",
      "3  NaN   93.5 NaN  NaN  barrel cortex, (approx) layer L1, Intan channe...   \n",
      "4  NaN  113.5 NaN  NaN  barrel cortex, (approx) layer L1, Intan channe...   \n",
      "\n",
      "                                            filtering  \\\n",
      "id                                                      \n",
      "0   Broadest possible hardware filters for Intan h...   \n",
      "1   Broadest possible hardware filters for Intan h...   \n",
      "2   Broadest possible hardware filters for Intan h...   \n",
      "3   Broadest possible hardware filters for Intan h...   \n",
      "4   Broadest possible hardware filters for Intan h...   \n",
      "\n",
      "                                                group    group_name  \\\n",
      "id                                                                    \n",
      "0   all_channels pynwb.ecephys.ElectrodeGroup at 0...  all_channels   \n",
      "1   all_channels pynwb.ecephys.ElectrodeGroup at 0...  all_channels   \n",
      "2   all_channels pynwb.ecephys.ElectrodeGroup at 0...  all_channels   \n",
      "3   all_channels pynwb.ecephys.ElectrodeGroup at 0...  all_channels   \n",
      "4   all_channels pynwb.ecephys.ElectrodeGroup at 0...  all_channels   \n",
      "\n",
      "                        reference  \n",
      "id                                 \n",
      "0   implanted stainless steel pin  \n",
      "1   implanted stainless steel pin  \n",
      "2   implanted stainless steel pin  \n",
      "3   implanted stainless steel pin  \n",
      "4   implanted stainless steel pin  \n"
     ]
    }
   ],
   "source": [
    "from dandi.dandiapi import DandiAPIClient\n",
    "from pynwb import NWBHDF5IO\n",
    "\n",
    "with DandiAPIClient() as client:\n",
    "    asset = client.get_dandiset(\"000231\").get_asset_by_path(\n",
    "        \"sub-KF134/sub-KF134_ses-20180211T154918_behavior+ecephys+image.nwb\"\n",
    "    )\n",
    "    url = asset.get_content_url(follow_redirects=1, strip_query=True)\n",
    "\n",
    "io = NWBHDF5IO(url, mode=\"r\", load_namespaces=True, driver=\"ros3\")\n",
    "nwb = io.read()\n",
    "\n",
    "# What's inside?\n",
    "print(\"Acquisition:\", list(nwb.acquisition.keys()))\n",
    "print(\"Processing:\", list(nwb.processing.keys()))\n",
    "print(\"Units:\", nwb.units if nwb.units else \"None\")\n",
    "print(\"Trials:\", nwb.trials.to_dataframe().head() if nwb.trials else \"None\")\n",
    "print(\"Electrodes:\", nwb.electrodes.to_dataframe().head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "314fc9c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "behavioral video: ['sub-KF134_ses-20180211T154918_behavior+ecephys+image/26871407-4821-4cd0-bde7-38e14b3c13ba_external_file_0.mkv']\n",
      "  rate: 200.0\n",
      "  starting_time: 0.0\n",
      "\n",
      "14 sorted units (from Kilosort+Phy)\n",
      "Columns: ['inhibitory', 'depth', 'layer', 'neuron_channel', 'spike_times', 'obs_intervals']\n",
      "\n",
      "Processing module 'behavior':\n",
      "  licks: BehavioralEvents\n",
      "  processed_position_whisker_C0: BehavioralTimeSeries\n",
      "  processed_position_whisker_C1: BehavioralTimeSeries\n",
      "  processed_position_whisker_C2: BehavioralTimeSeries\n",
      "  processed_position_whisker_C3: BehavioralTimeSeries\n",
      "  raw_position_whisker_C0: PoseEstimation\n",
      "  raw_position_whisker_C1: PoseEstimation\n",
      "  raw_position_whisker_C2: PoseEstimation\n",
      "  raw_position_whisker_C3: PoseEstimation\n",
      "  rewards: BehavioralEvents\n",
      "  contacts_by_whisker_C0: TimeIntervals\n",
      "  contacts_by_whisker_C1: TimeIntervals\n",
      "  contacts_by_whisker_C2: TimeIntervals\n",
      "  contacts_by_whisker_C3: TimeIntervals\n"
     ]
    }
   ],
   "source": [
    "from dandi.dandiapi import DandiAPIClient\n",
    "from pynwb import NWBHDF5IO\n",
    "\n",
    "\n",
    "with NWBHDF5IO(str(r\"C:\\Users\\aksel\\Documents\\Code\\EthoGraph\\data\\sub-KF134_ses-20180211T154918_behavior+ecephys+image.nwb\"), \"r\") as io:\n",
    "    nwb = io.read()\n",
    "\n",
    "    # Find video references\n",
    "    for name, obj in nwb.acquisition.items():\n",
    "        if hasattr(obj, 'external_file'):\n",
    "            print(f\"{name}: {obj.external_file[:]}\")\n",
    "            print(f\"  rate: {obj.rate}\")\n",
    "            print(f\"  starting_time: {obj.starting_time}\")\n",
    "\n",
    "    # Find processed data (Kilosort results are here as units)\n",
    "    if nwb.units:\n",
    "        units_df = nwb.units.to_dataframe()\n",
    "        print(f\"\\n{len(units_df)} sorted units (from Kilosort+Phy)\")\n",
    "        print(f\"Columns: {units_df.columns.tolist()}\")\n",
    "\n",
    "    # Processing modules often contain behavioral or LFP data\n",
    "    for mod_name, mod in nwb.processing.items():\n",
    "        print(f\"\\nProcessing module '{mod_name}':\")\n",
    "        for container_name in mod.data_interfaces:\n",
    "            print(f\"  {container_name}: {type(mod[container_name]).__name__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82dd2f66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f95e7e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921c0ae6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45a75cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sub-KF134/sub-KF134_ses-20180206T174211_behavior+image/b76384c3-94b4-479b-8169-9e8a7a833f6a_external_file_0.mkv\n"
     ]
    }
   ],
   "source": [
    "from dandi.dandiapi import DandiAPIClient\n",
    "from pathlib import Path\n",
    "\n",
    "client = DandiAPIClient()\n",
    "dandiset = client.get_dandiset(\"000231\", \"0.220904.1554\")\n",
    "\n",
    "for asset in dandiset.get_assets():\n",
    "    if \"KF134\" in asset.path and \"mkv\" in asset.path:\n",
    "        print(asset.path)\n",
    "        filepath = Path(asset.path)\n",
    "        filepath.parent.mkdir(parents=True, exist_ok=True)\n",
    "        asset.download(filepath)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "079265b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sub-KF134_ses-20180211T154918_behavior+ecephys+image/26871407-4821-4cd0-bde7-38e14b3c13ba_external_file_0.mkv']\n",
      "external\n"
     ]
    }
   ],
   "source": [
    "import pynwb\n",
    "\n",
    "with pynwb.NWBHDF5IO(r\"C:\\Users\\aksel\\Documents\\Code\\EthoGraph\\data\\sub-KF134_ses-20180211T154918_behavior+ecephys+image.nwb\", \"r\") as io:\n",
    "    nwb = io.read()\n",
    "    \n",
    "    video = nwb.acquisition[\"behavioral video\"]\n",
    "    print(video.external_file[:])  # This tells you the filename\n",
    "    print(video.format)            # Should be \"external\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f90f3a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'behavioral video': behavioral video pynwb.image.ImageSeries at 0x2111836426160\n",
      "Fields:\n",
      "  comments: All times in the NWB file are defined with respect to this video, which starts at 0 and proceeds at exactly 200 fps\n",
      "  conversion: 1.0\n",
      "  data: <HDF5 dataset \"data\": shape (0, 0, 0), type \"|u1\">\n",
      "  description: External file: behavioral video of whiskers\n",
      "  device: high-speed camera pynwb.device.Device at 0x2111832668256\n",
      "Fields:\n",
      "  description: DR1-D1312IE-100-G2-8\n",
      "  manufacturer: Photonfocus\n",
      "\n",
      "  dimension: <HDF5 dataset \"dimension\": shape (2,), type \"<i8\">\n",
      "  external_file: <StrDataset for HDF5 dataset \"external_file\": shape (1,), type \"|O\">\n",
      "  format: external\n",
      "  offset: 0.0\n",
      "  rate: 200.0\n",
      "  resolution: -1.0\n",
      "  starting_frame: [0]\n",
      "  starting_time: 0.0\n",
      "  starting_time_unit: seconds\n",
      "  unit: unknown\n",
      ", 'extracellular array recording': extracellular array recording pynwb.ecephys.ElectricalSeries at 0x2111839910608\n",
      "Fields:\n",
      "  comments: broken channels excluded. original sampling was at 30 kHz but timestamps here are converted to the common video timebase\n",
      "  conversion: 1.9499999999999999e-07\n",
      "  data: <HDF5 dataset \"data\": shape (65033216, 56), type \"<i2\">\n",
      "  description: all data from all channels, full-bandwidth, directly from the files saved by OpenEphys\n",
      "  electrodes: electrodes <class 'hdmf.common.table.DynamicTableRegion'>\n",
      "  filtering: between (approx) 1 and 7500 Hz using the OpenEphys Rhythm source module to set the hardware filters on the Intan RHD2132\n",
      "  offset: 0.0\n",
      "  rate: 29999.989041455377\n",
      "  resolution: 1.9499999999999999e-07\n",
      "  starting_time: 399.0283126054678\n",
      "  starting_time_unit: seconds\n",
      "  unit: volts\n",
      "}\n",
      "behavioral video: ImageSeries, shape: (0, 0, 0)\n",
      "extracellular array recording: ElectricalSeries, shape: (65033216, 56)\n"
     ]
    }
   ],
   "source": [
    "import pynwb\n",
    "\n",
    "with pynwb.NWBHDF5IO(r\"C:\\Users\\aksel\\Documents\\Code\\EthoGraph\\data\\sub-KF134_ses-20180211T154918_behavior+ecephys+image.nwb\", \"r\") as io:\n",
    "    nwb = io.read()\n",
    "    \n",
    "    # Check for video/image data\n",
    "    print(nwb.acquisition)\n",
    "    \n",
    "    # Look for ImageSeries\n",
    "    for name, obj in nwb.acquisition.items():\n",
    "        print(f\"{name}: {type(obj).__name__}, shape: {getattr(obj, 'data', None).shape if hasattr(obj, 'data') else 'N/A'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a409bd80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<HDF5 dataset \"external_file\": shape (1,), type \"|O\">\n",
      "(1,)\n",
      "[b'sub-KF134_ses-20180211T154918_behavior+ecephys+image/26871407-4821-4cd0-bde7-38e14b3c13ba_external_file_0.mkv']\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "\n",
    "f = h5py.File(r\"C:\\Users\\aksel\\Documents\\Code\\EthoGraph\\data\\sub-KF134_ses-20180211T154918_behavior+ecephys+image.nwb\", \"r\")\n",
    "\n",
    "# Navigate to the external_file dataset directly\n",
    "ext = f['acquisition']['behavioral video']['external_file']\n",
    "print(ext)\n",
    "print(ext.shape)\n",
    "print(ext[()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88ad83c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6efd6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import vocalpy as voc\n",
    "from ethograph.features.energy import meansquared\n",
    "\n",
    "sound = voc.Sound.read(\"path/to/audio.wav\")\n",
    "data = sound.data[0]  # first channel, 1-D\n",
    "sr = sound.samplerate\n",
    "\n",
    "env_time, envelope = meansquared(data, sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9a0c853",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(S3) C:\\Users\\aksel\\Downloads\\ONE\\openalyx.internationalbrainlab.org\\churchlandlab_ucla\\Subjects\\FD_28\\2023-12-01\\001\\raw_video_data\\_iblrig_leftCamera.raw.mp4: 100%|██████████| 8.10G/8.10G [12:04<00:00, 11.2MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aksel\\Downloads\\ONE\\openalyx.internationalbrainlab.org\\churchlandlab_ucla\\Subjects\\FD_28\\2023-12-01\\001\\raw_video_data\\_iblrig_leftCamera.raw.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "eid = eids[0]\n",
    "video_path = one.load_dataset(eid, 'raw_video_data/_iblrig_leftCamera.raw.mp4')\n",
    "print(video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5deddc01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbaceeda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579259cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cb8a00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4090a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dandi.dandiapi import DandiAPIClient\n",
    "from pathlib import Path\n",
    "\n",
    "dest = Path(r\"C:\\Users\\aksel\\Documents\\Code\\EthoGraph\\data\")\n",
    "\n",
    "with DandiAPIClient() as client:\n",
    "    ds = client.get_dandiset(\"000231\")\n",
    "    for asset in ds.get_assets():\n",
    "        if \"mkv\" in asset.path:\n",
    "            print(f\"Downloading: {asset.path} ({asset.size / 1e6:.1f} MB)\")\n",
    "            asset.download(dest / Path(asset.path).name)\n",
    "            print(\"Done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ethograph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
