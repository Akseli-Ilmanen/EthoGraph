{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "from pathlib import Path\n",
    "from ethograph.utils.io import TrialTree, set_media_files\n",
    "from movement.kinematics import compute_velocity, compute_speed\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def from_csv_with_behaviors(\n",
    "    file_path: Path | str,\n",
    "    fps: Optional[float] = None,\n",
    ") -> xr.Dataset:\n",
    "    \"\"\"Convert CSV with pose and behavior data to movement dataset.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    file_path : Path or str\n",
    "        Path to CSV file containing pose and behavior data\n",
    "    fps : float, optional\n",
    "        Frames per second of the video\n",
    "    source_software : str, optional\n",
    "        Name of the software that generated the data\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    xr.Dataset\n",
    "        Movement dataset with pose tracks (both aligned and absolute),\n",
    "        behavior labels, and position_type coordinate\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Extract metadata\n",
    "    keypoint_names = [\n",
    "        \"HeadF\", \"HeadB\", \"HeadL\", \"SpineF\", \"SpineM\", \"SpineL\",\n",
    "        \"Offset1\", \"Offset2\", \"HipL\", \"HipR\", \"ShoulderL\", \"ShoulderR\"\n",
    "    ]\n",
    "    individual_names = [\"an1\", \"an2\"]\n",
    "    position_types = [\"aligned\", \"absolute\"]\n",
    "    n_frames = len(df)\n",
    "    n_keypoints = len(keypoint_names)\n",
    "    n_individuals = len(individual_names)\n",
    "    n_space = 3  # x, y, z coordinates\n",
    "    n_position_types = len(position_types)\n",
    "    \n",
    "    # Initialize arrays with additional dimension for position type\n",
    "    position_array = np.zeros((n_frames, n_position_types, n_space, n_keypoints, n_individuals))\n",
    "    # Fix: confidence array should also have position_type dimension\n",
    "    confidence_array = np.ones((n_frames, n_position_types, n_keypoints, n_individuals))\n",
    "\n",
    "    \n",
    "    # Fill position data for both aligned and absolute\n",
    "    for p, pos_type in enumerate(position_types):\n",
    "        # Map our position types to the CSV column prefixes\n",
    "        csv_prefix = \"alignedPosition\" if pos_type == \"aligned\" else \"absolutePosition\"\n",
    "        \n",
    "        for i, individual in enumerate(individual_names):\n",
    "            for j, keypoint in enumerate(keypoint_names):\n",
    "                for k, coord in enumerate([\"x\", \"y\", \"z\"]):\n",
    "                    col_name = f\"{csv_prefix}_{individual}_{keypoint}_{coord}\"\n",
    "                    if col_name in df.columns:\n",
    "                        position_array[:, p, k, j, i] = df[col_name].values\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    time_coords = np.arange(n_frames, dtype=float) / fps\n",
    "\n",
    "    \n",
    "    # Create base dataset with position_type as a coordinate\n",
    "    ds = xr.Dataset(\n",
    "        data_vars={\n",
    "            \"position\": xr.DataArray(\n",
    "                position_array,\n",
    "                dims=[\"time\", \"position_type\", \"space\", \"keypoints\", \"individuals\"],\n",
    "            ),\n",
    "            \"confidence\": xr.DataArray(\n",
    "                confidence_array,\n",
    "                dims=[\"time\", \"position_type\", \"keypoints\", \"individuals\"], # confidence across space\n",
    "            ),\n",
    "        },\n",
    "        coords={\n",
    "            \"time\": time_coords,\n",
    "            \"position_type\": position_types,\n",
    "            \"space\": [\"x\", \"y\", \"z\"],\n",
    "            \"keypoints\": keypoint_names,\n",
    "            \"individuals\": individual_names,\n",
    "        },\n",
    "        attrs={\n",
    "            \"source_software\": \"DeepLabCut\", # for compatibility with movement napari\n",
    "            \"ds_type\": \"poses\",\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    ds.attrs[\"fps\"] = fps\n",
    "    \n",
    "    # Add behavioral annotations\n",
    "    behavior_mapping = {\n",
    "        \"behaviorCoarse_an1\": 0,\n",
    "        \"behaviorCoarse_an2\": 1,\n",
    "    }\n",
    "    behavior_coarse = np.full((n_frames, n_individuals), np.nan)\n",
    "\n",
    "    for col, ind_idx in behavior_mapping.items():\n",
    "        if col in df.columns:\n",
    "            behavior_coarse[:, ind_idx] = df[col].values\n",
    "    \n",
    "\n",
    "    ds[\"labels\"] = xr.DataArray(\n",
    "        behavior_coarse,\n",
    "        dims=[\"time\", \"individuals\"],\n",
    "        attrs={\n",
    "            \"description\": \"Coarse behavior annotations\",\n",
    "            \"classes\": [\n",
    "                \"Idle\", \"SmallMovement\", \"HeadTilt\", \"Groom\", \"Sniff\",\n",
    "                \"Investigate\", \"RearUp\", \"RearDown\", \"CrouchExplore\",\n",
    "                \"Amble\", \"Locomotion\"\n",
    "            ]\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # Add center of mass data if present\n",
    "    com_data = np.zeros((n_frames, n_space, n_individuals))\n",
    "    for i, individual in enumerate(individual_names):\n",
    "        for j, coord in enumerate([\"x\", \"y\", \"z\"]):\n",
    "            col_name = f\"centerOfmass_{individual}_{coord}\"\n",
    "            if col_name in df.columns:\n",
    "                com_data[:, j, i] = df[col_name].values\n",
    "    \n",
    "    ds[\"center_of_mass\"] = xr.DataArray(\n",
    "        com_data,\n",
    "        dims=[\"time\", \"space\", \"individuals\"],\n",
    "        attrs={\"description\": \"Center of mass for each individual\"}\n",
    "    )\n",
    "    \n",
    "    return ds\n",
    "\n",
    "\n",
    "\n",
    "ds_full = from_csv_with_behaviors(\n",
    "    r\"C:\\Users\\aksel\\Documents\\Code\\EthoGraph\\data\\20210119_Recording_SR1_SR2_social_vidtwo\\markerDataset.csv\",\n",
    "    fps=120,  # Set your actual fps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "CHUNK_SIZE = 3500\n",
    "VIDEO_DIR = Path(\"data/20210119_Recording_SR1_SR2_social_vidtwo/videos\")\n",
    "CAMERAS = [\"Camera1\", \"Camera2\", \"Camera3\", \"Camera4\", \"Camera5\", \"Camera6\"]\n",
    "N_FRAMES = 213500\n",
    "FPS = 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_paths_for_chunk(start_frame: int, video_dir: Path, cameras: list[str]) -> list[str]:\n",
    "    \"\"\"Get video file paths for a chunk based on its starting frame.\"\"\"\n",
    "    video_paths = []\n",
    "    for camera in cameras:\n",
    "        video_path = Path(camera) / f\"{start_frame}.mp4\"\n",
    "        video_paths.append(str(video_path))\n",
    "    return video_paths\n",
    "\n",
    "\n",
    "def split_dataset_into_chunks(\n",
    "    ds_full: xr.Dataset,\n",
    "    chunk_size: int,\n",
    "    video_dir: Path,\n",
    "    cameras: list[str],\n",
    "    fps: int,\n",
    ") -> list[xr.Dataset]:\n",
    "    \"\"\"Split a full dataset into fixed-size chunks with video assignments.\"\"\"\n",
    "    n_frames = ds_full.sizes[\"time\"]\n",
    "    n_chunks = n_frames // chunk_size\n",
    "    \n",
    "    datasets = []\n",
    "    \n",
    "    for i in range(n_chunks):\n",
    "        start_idx = i * chunk_size\n",
    "        end_idx = start_idx + chunk_size\n",
    "        start_frame = start_idx  # Frame number for video filename\n",
    "        \n",
    "        # Slice the dataset\n",
    "        ds_chunk = ds_full.isel(time=slice(start_idx, end_idx)).copy()\n",
    "        \n",
    "        # Reset time coordinate to start from 0 for each chunk\n",
    "        ds_chunk = ds_chunk.assign_coords(time=np.arange(chunk_size) / fps)\n",
    "        \n",
    "        # Set trial number\n",
    "        ds_chunk.attrs[\"trial\"] = i\n",
    "        ds_chunk.attrs[\"original_start_frame\"] = start_frame\n",
    "        \n",
    "        # Assign video files\n",
    "        video_paths = get_video_paths_for_chunk(start_frame, video_dir, cameras)\n",
    "        ds_chunk = set_media_files(ds_chunk, cameras=video_paths)\n",
    "        \n",
    "        ds_chunk[\"velocity\"] = compute_velocity(ds_chunk.position.sel(position_type='aligned'))\n",
    "        ds_chunk[\"velocity\"].attrs[\"type\"] = \"features\" \n",
    "        \n",
    "        \n",
    "        ds_chunk[\"speed\"] = compute_speed(ds_chunk.position.sel(position_type='aligned'))\n",
    "        ds_chunk[\"speed\"].attrs[\"type\"] = \"features\"\n",
    "        \n",
    "        ds_chunk.attrs[\"cameras\"] = [\"cam1\", \"cam2\", \"cam3\", \"cam4\", \"cam5\", \"cam6\"]\n",
    "        \n",
    "        datasets.append(ds_chunk)\n",
    "        \n",
    "    remaining = n_frames % chunk_size\n",
    "    if remaining > 0:\n",
    "        print(f\"Discarded {remaining} frames at the end (not a full chunk)\")\n",
    "    \n",
    "    print(f\"Created {len(datasets)} chunks of {chunk_size} frames each\")\n",
    "    return datasets, ds_chunk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discarded 3000 frames at the end (not a full chunk)\n",
      "Created 30 chunks of 3500 frames each\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset\n",
    "datasets, ds_chunk = split_dataset_into_chunks(\n",
    "    ds_full,\n",
    "    chunk_size=CHUNK_SIZE,\n",
    "    video_dir=VIDEO_DIR,\n",
    "    cameras=CAMERAS,\n",
    "    fps=FPS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted type_vars_dict: {'individuals': array(['an1', 'an2'], dtype='<U3'), 'features': ['velocity', 'speed'], 'cameras': array(['cam1', 'cam2', 'cam3', 'cam4', 'cam5', 'cam6'], dtype='<U4'), 'keypoints': array(['HeadF', 'HeadB', 'HeadL', 'SpineF', 'SpineM', 'SpineL', 'Offset1',\n",
      "       'Offset2', 'HipL', 'HipR', 'ShoulderL', 'ShoulderR'], dtype='<U9'), 'trial_conditions': ['original_start_frame']}\n",
      "Created TrialTree with 30 trials\n",
      "Trial numbers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]\n"
     ]
    }
   ],
   "source": [
    "# Create TrialTree from datasets\n",
    "dt = TrialTree.from_datasets(datasets)\n",
    "print(f\"Created TrialTree with {len(dt.trials)} trials\")\n",
    "print(f\"Trial numbers: {dt.trials}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to C:\\Users\\aksel\\Documents\\Code\\EthoGraph\\data\\20210119_Recording_SR1_SR2_social_vidtwo\\pair24.nc\n"
     ]
    }
   ],
   "source": [
    "# Save the TrialTree\n",
    "output_path = r\"C:\\Users\\aksel\\Documents\\Code\\EthoGraph\\data\\20210119_Recording_SR1_SR2_social_vidtwo\\pair24.nc\"\n",
    "dt.to_netcdf(output_path)\n",
    "print(f\"Saved to {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ethograph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
