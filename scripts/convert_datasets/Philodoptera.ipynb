{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Philodoptera Dataset Conversion\n",
    "\n",
    "Convert cricket tracking data to movement-compatible poses.csv format and then to TrialTree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from pathlib import Path\n",
    "from audioio import load_audio\n",
    "\n",
    "from movement.io import load_poses\n",
    "from movement.kinematics import compute_velocity, compute_speed, compute_acceleration\n",
    "\n",
    "from ethograph.utils.io import TrialTree, set_media_attrs, add_changepoints_to_ds\n",
    "from ethograph.features.audio_features import get_synced_envelope\n",
    "from ethograph.features.changepoints import find_troughs_binary, find_nearest_turning_points_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "paths",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = Path(r\"C:\\Users\\aksel\\Documents\\Code\\EthoGraph\\data\\Philodoptera\")\n",
    "\n",
    "pos_path = data_folder / \"exported_labels.csv\"\n",
    "audio_path = data_folder / \"audio.wav\"\n",
    "video_path = data_folder / \"video3.mp4\"\n",
    "\n",
    "fps = 240\n",
    "scorer = \"Akseli\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section1",
   "metadata": {},
   "source": [
    "## Step 1: Load and reshape raw tracking data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load_raw",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.read_csv(pos_path)\n",
    "print(f\"Raw data shape: {df_raw.shape}\")\n",
    "print(f\"Columns: {df_raw.columns.tolist()}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "df_raw.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reshape_data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data has alternating rows: even indices = left wingtip, odd indices = right wingtip\n",
    "# Each frame appears twice (once for each keypoint)\n",
    "\n",
    "x = df_raw[\"x\"].values.copy()\n",
    "y = df_raw[\"y\"].values.copy()\n",
    "frames = df_raw[\"frame\"].values\n",
    "\n",
    "# Replace 0 with NaN (missing tracking)\n",
    "x[x == 0] = np.nan\n",
    "y[y == 0] = np.nan\n",
    "\n",
    "# Split into left and right wingtips\n",
    "x_left = x[::2]    # even indices\n",
    "x_right = x[1::2]  # odd indices\n",
    "y_left = y[::2]\n",
    "y_right = y[1::2]\n",
    "frame_nums = frames[::2]  # unique frame numbers\n",
    "\n",
    "n_frames = len(frame_nums)\n",
    "print(f\"Number of frames: {n_frames}\")\n",
    "print(f\"Frame range: {frame_nums[0]} to {frame_nums[-1]}\")\n",
    "print(f\"Duration: {n_frames / fps:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section2",
   "metadata": {},
   "source": [
    "## Step 2: Create DLC-style DataFrame with multi-level header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create_dlc_df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DeepLabCut CSV format has multi-level columns:\n",
    "# Level 0: scorer\n",
    "# Level 1: bodyparts \n",
    "# Level 2: coords (x, y, likelihood)\n",
    "\n",
    "bodyparts = [\"LeftWingTip\", \"RightWingTip\"]\n",
    "coords = [\"x\", \"y\", \"likelihood\"]\n",
    "\n",
    "# Create multi-index columns\n",
    "columns = pd.MultiIndex.from_product(\n",
    "    [[scorer], bodyparts, coords],\n",
    "    names=[\"scorer\", \"bodyparts\", \"coords\"]\n",
    ")\n",
    "\n",
    "# Build data array: shape (n_frames, n_bodyparts * 3)\n",
    "# Order: LeftWingTip_x, LeftWingTip_y, LeftWingTip_likelihood, RightWingTip_x, ...\n",
    "likelihood = np.ones(n_frames)  # No confidence data, set to 1\n",
    "\n",
    "data = np.column_stack([\n",
    "    x_left, y_left, likelihood,\n",
    "    x_right, y_right, likelihood\n",
    "])\n",
    "\n",
    "df_dlc = pd.DataFrame(data, columns=columns)\n",
    "print(f\"DLC DataFrame shape: {df_dlc.shape}\")\n",
    "df_dlc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "save_dlc_csv",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as DLC-style CSV\n",
    "poses_csv_path = data_folder / \"poses.csv\"\n",
    "df_dlc.to_csv(poses_csv_path)\n",
    "print(f\"Saved DLC-style CSV to: {poses_csv_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section3",
   "metadata": {},
   "source": [
    "## Step 3: Load poses with movement library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load_movement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load using movement's from_dlc_style_df (directly from DataFrame)\n",
    "ds = load_poses.from_dlc_style_df(df_dlc, fps=fps)\n",
    "print(f\"Dataset dimensions: {dict(ds.dims)}\")\n",
    "print(f\"\\nData variables: {list(ds.data_vars)}\")\n",
    "print(f\"\\nCoordinates:\")\n",
    "for coord in ds.coords:\n",
    "    print(f\"  {coord}: {ds.coords[coord].values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verify_load",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the loaded data matches our original\n",
    "pos = ds.position.values\n",
    "print(f\"Position shape: {pos.shape}\")\n",
    "print(f\"  Expected: (time={n_frames}, space=2, keypoints=2, individuals=1)\")\n",
    "\n",
    "# Check first valid frame (around frame 306 based on original notebook)\n",
    "valid_idx = np.where(~np.isnan(x_left))[0][0]\n",
    "print(f\"\\nFirst valid frame index: {valid_idx}\")\n",
    "print(f\"Original LeftWingTip x,y: ({x_left[valid_idx]:.2f}, {y_left[valid_idx]:.2f})\")\n",
    "print(f\"Loaded position: {ds.position.isel(time=valid_idx, individuals=0).values}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section4",
   "metadata": {},
   "source": [
    "## Step 4: Compute kinematics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compute_kinematics",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds[\"velocity\"] = compute_velocity(ds.position)\n",
    "ds[\"speed\"] = compute_speed(ds.position)\n",
    "ds[\"acceleration\"] = compute_acceleration(ds.position)\n",
    "\n",
    "print(\"Added kinematics:\")\n",
    "for var in [\"velocity\", \"speed\", \"acceleration\"]:\n",
    "    print(f\"  {var}: {ds[var].dims}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section5",
   "metadata": {},
   "source": [
    "## Step 5: Add audio envelope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load_audio",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio, sr = load_audio(str(audio_path))\n",
    "print(f\"Audio shape: {audio.shape}\")\n",
    "print(f\"Sample rate: {sr} Hz\")\n",
    "print(f\"Audio duration: {audio.shape[0] / sr:.2f} seconds\")\n",
    "print(f\"Video duration: {n_frames / fps:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sync_audio",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get synced envelope (resampled to video fps)\n",
    "envelope, _ = get_synced_envelope(str(audio_path), sr, fps)\n",
    "print(f\"Envelope shape: {envelope.shape}\")\n",
    "print(f\"Expected frames: {n_frames}\")\n",
    "\n",
    "# Trim or pad envelope to match video frames\n",
    "if len(envelope) > n_frames:\n",
    "    envelope = envelope[:n_frames]\n",
    "    print(f\"Trimmed envelope to {n_frames} frames\")\n",
    "elif len(envelope) < n_frames:\n",
    "    envelope = np.pad(envelope, (0, n_frames - len(envelope)), mode='constant', constant_values=np.nan)\n",
    "    print(f\"Padded envelope to {n_frames} frames\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add_envelope",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add envelope to dataset\n",
    "ds[\"envelope\"] = xr.DataArray(\n",
    "    envelope,\n",
    "    dims=[\"time\"],\n",
    "    coords={\"time\": ds.coords[\"time\"]}\n",
    ")\n",
    "ds[\"envelope\"].attrs[\"type\"] = \"features\"\n",
    "\n",
    "# Store audio metadata\n",
    "ds.attrs[\"audio_sr\"] = sr\n",
    "ds.attrs[\"fps\"] = fps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section6",
   "metadata": {},
   "source": [
    "## Step 6: Add changepoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add_changepoints",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add changepoints on envelope (audio peaks/troughs)\n",
    "ds = add_changepoints_to_ds(\n",
    "    ds=ds,\n",
    "    target_feature=\"envelope\",\n",
    "    changepoint_name=\"troughs\",\n",
    "    changepoint_func=find_troughs_binary,\n",
    "    prominence=0.01,\n",
    "    distance=5\n",
    ")\n",
    "\n",
    "ds = add_changepoints_to_ds(\n",
    "    ds=ds,\n",
    "    target_feature=\"envelope\",\n",
    "    changepoint_name=\"turning_points\",\n",
    "    changepoint_func=find_nearest_turning_points_binary,\n",
    "    threshold=0.01,\n",
    "    max_value=1.0,\n",
    "    prominence=0.02,\n",
    "    width=2\n",
    ")\n",
    "\n",
    "print(\"Changepoint variables added:\")\n",
    "for var in ds.data_vars:\n",
    "    if \"changepoints\" in str(ds[var].attrs.get(\"type\", \"\")):\n",
    "        print(f\"  {var}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section7",
   "metadata": {},
   "source": [
    "## Step 7: Set media attributes and create TrialTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "set_attrs",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mark features\n",
    "for var in [\"position\", \"velocity\", \"speed\", \"acceleration\", \"confidence\"]:\n",
    "    if var in ds.data_vars:\n",
    "        ds[var].attrs[\"type\"] = \"features\"\n",
    "\n",
    "# Set media attributes\n",
    "ds = set_media_attrs(\n",
    "    ds,\n",
    "    cameras=[video_path.name],\n",
    "    mics=[audio_path.name],\n",
    "    tracking=[poses_csv_path.name],\n",
    "    tracking_prefix=\"dlc\"\n",
    ")\n",
    "\n",
    "# Add labels array (required for TrialTree)\n",
    "individuals = ds.coords[\"individuals\"].values\n",
    "ds[\"labels\"] = xr.DataArray(\n",
    "    np.zeros((len(ds.coords[\"time\"]), len(individuals))),\n",
    "    dims=[\"time\", \"individuals\"],\n",
    "    coords={\"time\": ds.coords[\"time\"], \"individuals\": individuals}\n",
    ")\n",
    "\n",
    "# Set trial attribute\n",
    "ds.attrs[\"trial\"] = \"stridulation_1\"\n",
    "ds.attrs[\"source_software\"] = \"DeepLabCut\"\n",
    "\n",
    "print(\"Dataset attributes:\")\n",
    "for k, v in ds.attrs.items():\n",
    "    print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create_trialtree",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TrialTree\n",
    "dt = TrialTree.from_datasets([ds])\n",
    "print(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "save_trialtree",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to NetCDF\n",
    "output_path = data_folder / \"Philodoptera.nc\"\n",
    "dt.to_netcdf(output_path)\n",
    "print(f\"Saved TrialTree to: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section8",
   "metadata": {},
   "source": [
    "## Step 8: Verify and visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verify_load_back",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load back and verify\n",
    "dt_loaded = TrialTree.load(str(output_path))\n",
    "print(dt_loaded)\n",
    "print(f\"\\nTrials: {dt_loaded.trials}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot_data",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ds_trial = dt_loaded.itrial(0)\n",
    "time = ds_trial.coords[\"time\"].values\n",
    "\n",
    "fig, axs = plt.subplots(3, 1, figsize=(14, 8), sharex=True)\n",
    "\n",
    "# Plot envelope\n",
    "axs[0].plot(time, ds_trial[\"envelope\"].values, color=\"green\", alpha=0.7)\n",
    "axs[0].set_ylabel(\"Audio Envelope\")\n",
    "axs[0].set_title(\"Philodoptera Stridulation Dataset\")\n",
    "\n",
    "# Plot x positions\n",
    "pos = ds_trial[\"position\"].sel(space=\"x\", individuals=\"individual_0\").values\n",
    "for i, kp in enumerate(ds_trial.coords[\"keypoints\"].values):\n",
    "    axs[1].plot(time, pos[:, i], label=kp)\n",
    "axs[1].set_ylabel(\"X Position (px)\")\n",
    "axs[1].legend()\n",
    "\n",
    "# Plot speed\n",
    "speed = ds_trial[\"speed\"].sel(individuals=\"individual_0\").values\n",
    "for i, kp in enumerate(ds_trial.coords[\"keypoints\"].values):\n",
    "    axs[2].plot(time, speed[:, i], label=kp)\n",
    "axs[2].set_ylabel(\"Speed (px/s)\")\n",
    "axs[2].set_xlabel(\"Time (s)\")\n",
    "axs[2].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
